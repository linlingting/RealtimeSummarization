
\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts}

\author{Lingting Lin, Yunjie Wang, Chen Lin}
\title{Realtime Event Summarization}
\begin{document}
\maketitle
\section{Introduction}
%Motivation: why do we need event summarization

%Event summarization should be real time

%Related Work: focus on extractive methods. cons: add a representative tweet

%Three Scenarios when we need to update a summary (1) better candidate for a brief summary (2) conflicting information (3) outdated summary

%Re-computation is infeasible (1) streaming text (2) realtime response

%Another challenge: similarity content + structure 

%Intuitiion: macro-level: incremental computation; micro-level: structure similarity measurments only when needed

%present work: based on simplex method 

%contribution: a novel problem

%paper structure

\section{Related Work}
%Event summarization

\section{Static Summarization}
\subsection{Problem Definition}
Suppose that we have $N$ tweets to be summarized, within which $M$ tweets are credible and relevant. We are going to select a few representative posts from the tweet universe to form the summary. To model this problem, we use a vector $\tilde{\mathbf{x}}\in R^N$ , where each element $\tilde{\mathbf{x}}_j\in \{0,1\}$ is a binary variable. If a tweet $i$ is chosen as the abstractive sentence, the corresponding $\tilde{\mathbf{x}}_i=1$ . Otherwise, we set  $\tilde{\mathbf{x}}_i=0$. We use another $N$-dim vector $\tilde{\mathbf{c}}\in R^M$ to describe the loss of choosing each tweet as a candidate. $\tilde{\mathbf{A}}\in R^{M\times N}$  is a similarity matrix, where $\tilde{a}_{i,j}$  is the similarity between a credible and relevant tweet $i$ and a candidate tweet $j$ in the tweet universe. $\mathbf{b}\in R^{M}$ is a weight vector, where $b_{i}$ indicates the importance of $i$ being covered in the summary. Our objective is to

\begin{equation*}
\min \tilde{\mathbf{c}}^T\tilde{\mathbf{x}}\textrm{ subject to } \tilde{\mathbf{A}}\tilde{\mathbf{x}}\geq \mathbf{b}, \tilde{\mathbf{x}}\in \{0,1\}
\end{equation*}

\subsection{Methodology Overview}
We first transform it to a standard form of bounded linear programming problem by making the following adjustments: $\mathbf{c}=[\tilde{\mathbf{c}},\mathbf{0}],\mathbf{x}=[\tilde{\mathbf{x}},\mathbf{z}]^T,\mathbf{A}=[\tilde{\mathbf{A}},-\mathbf{I}]$, where $\mathbf{I}$ is the $M\times M$ identity matrix. Therefore we have

\begin{equation}
\min \mathbf{cx} \textrm{ subject to } \mathbf{Ax} = \mathbf{b}, \mathbf{x}\geq \mathbf{0},\tilde{\mathbf{x}} \leq \mathbf{1}
\end{equation}

We modify the LP so that there is an easy choice of basic solution. We start by solving

\begin{equation}
\min \mathbf{e^{T}s} \textrm{ subject to } \mathbf{Ax} + \mathbf{Is} = \mathbf{b}, \mathbf{x}\geq \mathbf{0},\tilde{\mathbf{x}} \leq \mathbf{1},\mathbf{s}\geq \mathbf{0}
\end{equation}

where $\mathbf{e}$ is the vector of all ones, $\mathbf{s}$ are called artificial variables,and $b_{i}\geq \mathbf{0}$.
To solve the above LP relaxation, we adopt the bounded simplex method. In each iterate, only $M$ variables are selected as the basic points. Suppose $\mathbf{A}_{,j}$ is the $j$th column, and the corresponding columns of basic variables in $\mathbf{A}$ are denoted as $\mathbf{A_B}$,others are denoted as $\mathbf{A_N}$. Non-basic variables are either at upper bound ($j \in U$) or at lower bound ($j\in L$).

Define $\mathbf{c}=[\mathbf{e},\mathbf{0}], \mathbf{x}^{'} = [\mathbf{x},\mathbf{s}]^T$ and $\mathbf{A}^{'} = [\mathbf{A},\mathbf{I}]$ so that the constraints of the modified LP can be written as $\mathbf{A}^{'}\mathbf{x}^{'} = \mathbf{b}, \mathbf{x}^{'} \geq \mathbf{0},\tilde{\mathbf{x}} \leq \mathbf{1}$.

Step 1: Solve $\mathbf{x_B^{'}} = \mathbf{A_B^{'}}^{-1}(\mathbf{b} - \mathbf{u})$, where $\mathbf{u} = \Sigma_{j\in U} \mathbf{A}_{,j}^{'}$.
Let $\mathbf{B}$ be the indices of the artificial variables and set the all non-basic variables to be $x_j=0$. Then $\mathbf{B}$ is a basis,since the corresponding columns of $\mathbf{A_B^{'}}$ are $\mathbf{I}$, the identity,the corresponding basic feasible solution is $\mathbf{x} = \mathbf{0}, \mathbf{z} = \mathbf{b}$.

Step 2: Pricing. $\mathbf{y} = {\mathbf{B}^T}^{-1}\mathbf{e_B}$

Step 3: Compute $\bar{c_j} = c_j - y^T\mathbf{A}_{,j}^{'}$. If $x_j = 0, \bar{c_j} > 0$ and $x_j = 1,\bar{c_j} < 0$, then the problem is solved. Else pick $q$ the most contradictive variable, i.e. the most negative $\bar{c_q}$ for $x_q = 0$ as the entering index.

Step 4: $d = \mathbf{B}^{-1}\mathbf{A}_{,q}^{'}$.

Step 5: There are three subcases as follows:

If $q \in \{ \mathbf{z_N}, \mathbf{s_N}\}$, caculate $\min_i \left\{\{\frac{x_{\mathbf{B}_{i}}}{d_i}, \frac{s_{\mathbf{B}_{i}}}{d_i}, \frac{z_{\mathbf{B}_{i}}}{d_i}\} \forall d_i>0, \{\frac{x_{\mathbf{B}_{i}}-1}{d_i}\} \forall d_i<0\right\}$.
Let $p=i, x_q^{new} = min, \mathbf{x}_{\mathbf{B}^{old}}^{'new} = \mathbf{x}_{\mathbf{B}^{old}}^{'old} - dx_q^{new}, \mathbf{B}^{new} \leftarrow \mathbf{B}^{old} - \{p\} \bigcup \{q\}.$

If $q \in L$,  caculate $\min_i \left\{\{\frac{x_{\mathbf{B}_{i}}}{d_i}, \frac{s_{\mathbf{B}_{i}}}{d_i}, \frac{z_{\mathbf{B}_{i}}}{d_i}\} \forall d_i>0, \{\frac{x_{\mathbf{B}_{i}}-1}{d_i}\} \forall d_i<0, 1 \right\}, x_q^{new} = min,
\mathbf{x}_{\mathbf{B}^{old}}^{'new} = \mathbf{x}_{\mathbf{B}^{old}}^{'old} - dx_q^{new}$. If $x_q^{new} \neq 1$, let $p=i, \mathbf{B}^{new} \leftarrow \mathbf{B}^{old} - \{p\} \bigcup \{q\}.$

If $q \in U$,  caculate $\min_i \left\{\{\frac{x_{\mathbf{B}_{i}}}{-d_i}, \frac{s_{\mathbf{B}_{i}}}{-d_i}, \frac{z_{\mathbf{B}_{i}}}{-d_i}\} \forall d_i<0, \{\frac{1-x_{\mathbf{B}_{i}}}{d_i}\} \forall d_i>0, 1 \right\}, x_q^{new} = 1 - min, \mathbf{x}_{\mathbf{B}^{old}}^{'new} = \mathbf{x}_{\mathbf{B}^{old}}^{'old} + d(1-x_q^{new})$. If $x_q^{new} \neq 0$, let $p=i, \mathbf{B}^{new} \leftarrow \mathbf{B}^{old} - \{p\} \bigcup \{q\}.$

Step 6: If all artificial variables are non-basic or some artificial variables are in the basis but all $x_{z_i} = 0$ then go to Step 7,otherwise return to Step 2.

Step 7: If some artificial variables are in the basis,remove them from basis. Change $\mathbf{c}=[\tilde{\mathbf{c}},\mathbf{0}]$ , repeat Step 2 to Step 5.


\section{Update Summarization}

%first show that we don't need A by proving the constraint 1 hold by itself for all scenarios (conflicting, outdate, better converage)
\begin{equation}
\min c_0x_0+c_1x_1\\
s.t. \begin{bmatrix}
A & D \\ 
D^T & B
\end{bmatrix}\begin{bmatrix}
 x_0\\
x_1 
\end{bmatrix}\geq \begin{bmatrix}
b_0\\
b_1 
\end{bmatrix}
\end{equation}

%check whether constraint 2 is satisfied, note that D is small due to the sparseness of x_0
$D^Tx_0\geq b_1$

%if b_1 largely not covered, outdated, change constraint


%else implement simplex

%if an index gets out, check if its conflicting by measuring structural similarity


\end{document}